{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Partition PySpark",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMoAmc+LaMg8uRU/MHOUmVm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahemon/PySpark-practice/blob/main/Partition_PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "yWmJ8y_QSarc",
        "outputId": "9ae9df6e-5c0c-4d14-c9d7-c7924186e3f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [Connected to cloud\r0% [1 InRelease gpgv 1,581 B] [Connecting to archive.ubuntu.com] [Waiting for h\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [1 InRelease gpgv 1,581 B] [Connecting to archive.ubuntu.com] [Waiting for h\r                                                                               \rHit:3 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "\r0% [1 InRelease gpgv 1,581 B] [Connecting to archive.ubuntu.com] [Connecting to\r                                                                               \rIgn:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fc6e65f9d90>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://8727038f2e84:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v2.3.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-2.3.1/spark-2.3.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.3.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.3.1-bin-hadoop2.7\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark import SparkContext\n",
        "sc = SparkContext.getOrCreate()\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate() \n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.sqlshack.com/sql-lag-function-overview-and-examples/  \n",
        "\n",
        "\n",
        "https://sparkbyexamples.com/pyspark/pyspark-window-functions/\n",
        "\n",
        "https://stackoverflow.com/questions/57525149/spark-how-to-aggregate-reduce-records-based-on-time-difference\n"
      ],
      "metadata": {
        "id": "mwe1GQI2lLIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
        "\n",
        "simpleData = ((\"James\", \"Sales\", 3000), \\\n",
        "    (\"Michael\", \"Sales\", 4600),  \\\n",
        "    (\"Robert\", \"Sales\", 4100),   \\\n",
        "    (\"Maria\", \"Finance\", 3000),  \\\n",
        "    (\"James\", \"Sales\", 3000),    \\\n",
        "    (\"Scott\", \"Finance\", 3300),  \\\n",
        "    (\"Jen\", \"Finance\", 3900),    \\\n",
        "    (\"Jeff\", \"Marketing\", 3000), \\\n",
        "    (\"Kumar\", \"Marketing\", 2000),\\\n",
        "    (\"Saif\", \"Sales\", 4100) \\\n",
        "  )\n",
        " \n",
        "columns= [\"employee_name\", \"department\", \"salary\"]\n",
        "simpleData = spark.createDataFrame(data = simpleData, schema = columns)\n",
        "simpleData.printSchema()\n",
        "simpleData.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "br3gqRZ3SgGm",
        "outputId": "53a1533f-c2cf-4d22-807f-96fb7469571b"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- employee_name: string (nullable = true)\n",
            " |-- department: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n",
            "+-------------+----------+------+\n",
            "|employee_name|department|salary|\n",
            "+-------------+----------+------+\n",
            "|James        |Sales     |3000  |\n",
            "|Michael      |Sales     |4600  |\n",
            "|Robert       |Sales     |4100  |\n",
            "|Maria        |Finance   |3000  |\n",
            "|James        |Sales     |3000  |\n",
            "|Scott        |Finance   |3300  |\n",
            "|Jen          |Finance   |3900  |\n",
            "|Jeff         |Marketing |3000  |\n",
            "|Kumar        |Marketing |2000  |\n",
            "|Saif         |Sales     |4100  |\n",
            "+-------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import rank,dense_rank"
      ],
      "metadata": {
        "id": "7QwmBtGSWLaD"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number\n",
        "windowSpec  = Window.partitionBy(\"department\").orderBy(\"salary\")\n",
        "\n",
        "simpleData.withColumn(\"row_number\",dense_rank().over(windowSpec)).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_gfribzWNli",
        "outputId": "0baeb2dc-7333-4d2b-a28e-8927c9bf921d"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+----------+\n",
            "|employee_name|department|salary|row_number|\n",
            "+-------------+----------+------+----------+\n",
            "|James        |Sales     |3000  |1         |\n",
            "|James        |Sales     |3000  |1         |\n",
            "|Robert       |Sales     |4100  |2         |\n",
            "|Saif         |Sales     |4100  |2         |\n",
            "|Michael      |Sales     |4600  |3         |\n",
            "|Maria        |Finance   |3000  |1         |\n",
            "|Scott        |Finance   |3300  |2         |\n",
            "|Jen          |Finance   |3900  |3         |\n",
            "|Kumar        |Marketing |2000  |1         |\n",
            "|Jeff         |Marketing |3000  |2         |\n",
            "+-------------+----------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number\n",
        "windowSpec  = Window.partitionBy(\"department\").orderBy(\"salary\")\n",
        "simpleData.withColumn(\"row_number\",rank().over(windowSpec)).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoqwJDNSWPui",
        "outputId": "bef8ce17-798b-4794-a738-323d84178e73"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+----------+\n",
            "|employee_name|department|salary|row_number|\n",
            "+-------------+----------+------+----------+\n",
            "|James        |Sales     |3000  |1         |\n",
            "|James        |Sales     |3000  |1         |\n",
            "|Robert       |Sales     |4100  |3         |\n",
            "|Saif         |Sales     |4100  |3         |\n",
            "|Michael      |Sales     |4600  |5         |\n",
            "|Maria        |Finance   |3000  |1         |\n",
            "|Scott        |Finance   |3300  |2         |\n",
            "|Jen          |Finance   |3900  |3         |\n",
            "|Kumar        |Marketing |2000  |1         |\n",
            "|Jeff         |Marketing |3000  |2         |\n",
            "+-------------+----------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lag    \n",
        "windowSpec  = Window.partitionBy(\"department\").orderBy(\"salary\")\n",
        "simpleData.withColumn(\"lag\",lag(\"salary\",2).over(windowSpec)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTQMuNwGWRTC",
        "outputId": "774244d5-4f06-49d4-8b35-78e9f95f6e6b"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+----+\n",
            "|employee_name|department|salary| lag|\n",
            "+-------------+----------+------+----+\n",
            "|        James|     Sales|  3000|null|\n",
            "|        James|     Sales|  3000|null|\n",
            "|       Robert|     Sales|  4100|3000|\n",
            "|         Saif|     Sales|  4100|3000|\n",
            "|      Michael|     Sales|  4600|4100|\n",
            "|        Maria|   Finance|  3000|null|\n",
            "|        Scott|   Finance|  3300|null|\n",
            "|          Jen|   Finance|  3900|3000|\n",
            "|        Kumar| Marketing|  2000|null|\n",
            "|         Jeff| Marketing|  3000|null|\n",
            "+-------------+----------+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pyspark.sql.functions.lag(col, offset=1, default=None)    #offsetint -> number of row to extend  default-> default value\n",
        "from pyspark.sql.functions import lag,row_number \n",
        "from pyspark.sql.window import Window   \n",
        "windowSpec  = Window.partitionBy(\"department\").orderBy(\"salary\")\n",
        "simpleData.withColumn(\"lag\",lag(\"salary\",1,1).over(windowSpec)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqS9F1dMZT5q",
        "outputId": "1e7831a8-cabf-4f2b-9ad5-78b21d4b4103"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+------+----+\n",
            "|employee_name|department|salary|newcol| lag|\n",
            "+-------------+----------+------+------+----+\n",
            "|        James|     Sales|  3000|  null|   1|\n",
            "|        James|     Sales|  3000|  3000|3000|\n",
            "|       Robert|     Sales|  4100|  3000|3000|\n",
            "|         Saif|     Sales|  4100|  4100|4100|\n",
            "|      Michael|     Sales|  4600|  4100|4100|\n",
            "|        Maria|   Finance|  3000|  null|   1|\n",
            "|        Scott|   Finance|  3300|  3000|3000|\n",
            "|          Jen|   Finance|  3900|  3300|3300|\n",
            "|        Kumar| Marketing|  2000|  null|   1|\n",
            "|         Jeff| Marketing|  3000|  2000|2000|\n",
            "+-------------+----------+------+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"lead\"\"\"\n",
        "from pyspark.sql.functions import lead    \n",
        "simpleData.withColumn(\"lead\",lead(\"salary\",2).over(windowSpec)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dgb_TnIcZEcB",
        "outputId": "38bdfa34-3aae-45b2-e504-a41e306f6235"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+----+\n",
            "|employee_name|department|salary|lead|\n",
            "+-------------+----------+------+----+\n",
            "|        James|     Sales|  3000|4100|\n",
            "|        James|     Sales|  3000|4100|\n",
            "|       Robert|     Sales|  4100|4600|\n",
            "|         Saif|     Sales|  4100|null|\n",
            "|      Michael|     Sales|  4600|null|\n",
            "|        Maria|   Finance|  3000|3900|\n",
            "|        Scott|   Finance|  3300|null|\n",
            "|          Jen|   Finance|  3900|null|\n",
            "|        Kumar| Marketing|  2000|null|\n",
            "|         Jeff| Marketing|  3000|null|\n",
            "+-------------+----------+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lag    \n",
        "windowSpec  = Window.partitionBy(\"department\").orderBy(\"salary\")\n",
        "simpleData=simpleData.withColumn(\"newcol\",lag(\"salary\",1).over(windowSpec))"
      ],
      "metadata": {
        "id": "59TGhw7SZJyg"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simpleData.show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR9qtUtBaP6w",
        "outputId": "e09c784e-ed38-4104-be34-5798b1d760e5"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+------+\n",
            "|employee_name|department|salary|newcol|\n",
            "+-------------+----------+------+------+\n",
            "|        James|     Sales|  3000|  null|\n",
            "|        James|     Sales|  3000|  3000|\n",
            "+-------------+----------+------+------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simpleData.withColumn(\"diff\",simpleData['newcol']-simpleData['salary']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dC-pP-UWc4IX",
        "outputId": "34f0c3c0-7432-4c10-84a3-3bb5ac9973dd"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+------+-----+\n",
            "|employee_name|department|salary|newcol| diff|\n",
            "+-------------+----------+------+------+-----+\n",
            "|        James|     Sales|  3000|  null| null|\n",
            "|        James|     Sales|  3000|  3000|    0|\n",
            "|       Robert|     Sales|  4100|  3000|-1100|\n",
            "|         Saif|     Sales|  4100|  4100|    0|\n",
            "|      Michael|     Sales|  4600|  4100| -500|\n",
            "|        Maria|   Finance|  3000|  null| null|\n",
            "|        Scott|   Finance|  3300|  3000| -300|\n",
            "|          Jen|   Finance|  3900|  3300| -600|\n",
            "|        Kumar| Marketing|  2000|  null| null|\n",
            "|         Jeff| Marketing|  3000|  2000|-1000|\n",
            "+-------------+----------+------+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "gELYFl9gdo-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Speed DataSet"
      ],
      "metadata": {
        "id": "GgxpfScem0ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sDb = ((1,1538204192 , 44.55), \\\n",
        "       (1, 1538204193, 47.20), \\\n",
        "     (1,1538204194 , 42.14), \\\n",
        "     (1,1538204195 , 39.20), \\\n",
        "     (1, 1538204196, 35.30), \\\n",
        "     (1, 1538204197, 32.22), \\\n",
        "     (1, 1538204198, 34.80), \\\n",
        "    (1, 1538204199, 37.10), \\\n",
        "    (1, 1538204221, 55.30), \\\n",
        "    (1, 1538204222, 57.20), \\\n",
        "  (1, 1538204223, 54.60), \\\n",
        "  (1, 1538204224, 52.15), \\\n",
        "  (1, 1538204224, 49.27), \\\n",
        "   (1, 1538204225, 47.89), \\\n",
        "   (1, 1538204226, 50.57), \\\n",
        "  (1, 1538204227, 53.72))\n",
        " \n",
        "columns= [\"trip_id\", \"timestamp\", \"speed\"]\n",
        "sDb = spark.createDataFrame(data = sDb, schema = columns)\n",
        "sDb.printSchema()\n",
        "sDb.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APsbZc3sm276",
        "outputId": "0b0affeb-9dfc-40e3-986d-c620fa8debcb"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- trip_id: long (nullable = true)\n",
            " |-- timestamp: long (nullable = true)\n",
            " |-- speed: double (nullable = true)\n",
            "\n",
            "+-------+----------+-----+\n",
            "|trip_id|timestamp |speed|\n",
            "+-------+----------+-----+\n",
            "|1      |1538204192|44.55|\n",
            "|1      |1538204193|47.2 |\n",
            "|1      |1538204194|42.14|\n",
            "|1      |1538204195|39.2 |\n",
            "|1      |1538204196|35.3 |\n",
            "|1      |1538204197|32.22|\n",
            "|1      |1538204198|34.8 |\n",
            "|1      |1538204199|37.1 |\n",
            "|1      |1538204221|55.3 |\n",
            "|1      |1538204222|57.2 |\n",
            "|1      |1538204223|54.6 |\n",
            "|1      |1538204224|52.15|\n",
            "|1      |1538204224|49.27|\n",
            "|1      |1538204225|47.89|\n",
            "|1      |1538204226|50.57|\n",
            "|1      |1538204227|53.72|\n",
            "+-------+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lag,row_number,when,lead,concat\n",
        "from pyspark.sql.window import Window "
      ],
      "metadata": {
        "id": "QpzHFwC-n38g"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overColumns = Window.partitionBy(\"trip_id\").orderBy(\"timestamp\")\n",
        "breaksDF = sDb.withColumn(\"speeddiff\", sDb['speed']-lag(sDb['speed'], 1,0).over(overColumns))"
      ],
      "metadata": {
        "id": "Gzkya3jXpD6U"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "breaksDF.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PAlSWbJpjVj",
        "outputId": "25d9b870-79b4-4578-b3c1-ea4f648d04cd"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-----+-------------------+\n",
            "|trip_id| timestamp|speed|          speeddiff|\n",
            "+-------+----------+-----+-------------------+\n",
            "|      1|1538204192|44.55|              44.55|\n",
            "|      1|1538204193| 47.2| 2.6500000000000057|\n",
            "|      1|1538204194|42.14| -5.060000000000002|\n",
            "|      1|1538204195| 39.2|-2.9399999999999977|\n",
            "|      1|1538204196| 35.3|-3.9000000000000057|\n",
            "+-------+----------+-----+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as F\n",
        "brEvent = breaksDF.withColumn('breaking',F.when((breaksDF['speeddiff'] < 1), 1).otherwise(0))"
      ],
      "metadata": {
        "id": "lHWQ9AKaqjih"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brEvent.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqCBC4Fiv3YU",
        "outputId": "11633adf-3abb-40b9-8140-78dbbdfc8a4b"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-----+-------------------+--------+\n",
            "|trip_id| timestamp|speed|          speeddiff|breaking|\n",
            "+-------+----------+-----+-------------------+--------+\n",
            "|      1|1538204192|44.55|              44.55|       0|\n",
            "|      1|1538204193| 47.2| 2.6500000000000057|       0|\n",
            "|      1|1538204194|42.14| -5.060000000000002|       1|\n",
            "|      1|1538204195| 39.2|-2.9399999999999977|       1|\n",
            "|      1|1538204196| 35.3|-3.9000000000000057|       1|\n",
            "|      1|1538204197|32.22|-3.0799999999999983|       1|\n",
            "|      1|1538204198| 34.8| 2.5799999999999983|       0|\n",
            "|      1|1538204199| 37.1| 2.3000000000000043|       0|\n",
            "|      1|1538204221| 55.3| 18.199999999999996|       0|\n",
            "|      1|1538204222| 57.2| 1.9000000000000057|       0|\n",
            "|      1|1538204223| 54.6|-2.6000000000000014|       1|\n",
            "|      1|1538204224|52.15| -2.450000000000003|       1|\n",
            "|      1|1538204224|49.27|-2.8799999999999955|       1|\n",
            "|      1|1538204225|47.89|-1.3800000000000026|       1|\n",
            "|      1|1538204226|50.57| 2.6799999999999997|       0|\n",
            "|      1|1538204227|53.72| 3.1499999999999986|       0|\n",
            "+-------+----------+-----+-------------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputDF = brEvent.withColumn(\"breakevent\", F.when((brEvent['breaking'] - lag(brEvent['breaking'], 1).over(overColumns)) == 1, \"start of break\").when((outputDF['breaking'] - lead(outputDF['breaking'], 1).over(overColumns)) == 1, \"end of break\"))"
      ],
      "metadata": {
        "id": "Fp04RSEGxkPS"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#outputDF2 = outputDF.withColumn(\"breakevent\", F.when((outputDF['breaking'] - lead(outputDF['breaking'], 1).over(overColumns)) == 1, \"end of break\"))"
      ],
      "metadata": {
        "id": "pCgh0kz33iNw"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputDF.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5LYvXgtycPS",
        "outputId": "8d53fc14-f9b6-46a3-d716-99dcef49fab3"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-----+-------------------+--------+--------------+\n",
            "|trip_id| timestamp|speed|          speeddiff|breaking|    breakevent|\n",
            "+-------+----------+-----+-------------------+--------+--------------+\n",
            "|      1|1538204192|44.55|              44.55|       0|          null|\n",
            "|      1|1538204193| 47.2| 2.6500000000000057|       0|          null|\n",
            "|      1|1538204194|42.14| -5.060000000000002|       1|start of break|\n",
            "|      1|1538204195| 39.2|-2.9399999999999977|       1|          null|\n",
            "|      1|1538204196| 35.3|-3.9000000000000057|       1|          null|\n",
            "|      1|1538204197|32.22|-3.0799999999999983|       1|  end of break|\n",
            "|      1|1538204198| 34.8| 2.5799999999999983|       0|          null|\n",
            "|      1|1538204199| 37.1| 2.3000000000000043|       0|          null|\n",
            "|      1|1538204221| 55.3| 18.199999999999996|       0|          null|\n",
            "|      1|1538204222| 57.2| 1.9000000000000057|       0|          null|\n",
            "|      1|1538204223| 54.6|-2.6000000000000014|       1|start of break|\n",
            "|      1|1538204224|52.15| -2.450000000000003|       1|          null|\n",
            "|      1|1538204224|49.27|-2.8799999999999955|       1|          null|\n",
            "|      1|1538204225|47.89|-1.3800000000000026|       1|  end of break|\n",
            "|      1|1538204226|50.57| 2.6799999999999997|       0|          null|\n",
            "|      1|1538204227|53.72| 3.1499999999999986|       0|          null|\n",
            "+-------+----------+-----+-------------------+--------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputDF.filter(\"breakevent is not null\").select(\"trip_id\", \"timestamp\", \"speed\", \"breakevent\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpPDAqlRzBjO",
        "outputId": "aedb2a2a-18bb-4ee2-a91e-d6488a9861a0"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-----+--------------+\n",
            "|trip_id| timestamp|speed|    breakevent|\n",
            "+-------+----------+-----+--------------+\n",
            "|      1|1538204194|42.14|start of break|\n",
            "|      1|1538204197|32.22|  end of break|\n",
            "|      1|1538204223| 54.6|start of break|\n",
            "|      1|1538204225|47.89|  end of break|\n",
            "+-------+----------+-----+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import first,last"
      ],
      "metadata": {
        "id": "WKBk_DE4FojJ"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputDF.filter(\"breakevent is not null\").withColumn(\"breakID\", when(outputDF['breakevent'] == \"start of break\", concat(outputDF['trip_id'],outputDF['timestamp'])).when(outputDF['breakevent'] == \"end of break\", concat(outputDF['trip_id'], lag(outputDF['timestamp'], 1).over(overColumns)))).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AICPUzy15zuh",
        "outputId": "4629eff2-27a8-4140-f29d-7ce2fd7c61bd"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-----+-------------------+--------+--------------+-----------+\n",
            "|trip_id| timestamp|speed|          speeddiff|breaking|    breakevent|    breakID|\n",
            "+-------+----------+-----+-------------------+--------+--------------+-----------+\n",
            "|      1|1538204194|42.14| -5.060000000000002|       1|start of break|11538204194|\n",
            "|      1|1538204197|32.22|-3.0799999999999983|       1|  end of break|11538204194|\n",
            "|      1|1538204223| 54.6|-2.6000000000000014|       1|start of break|11538204223|\n",
            "|      1|1538204225|47.89|-1.3800000000000026|       1|  end of break|11538204223|\n",
            "+-------+----------+-----+-------------------+--------+--------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputDF.filter(\"breakevent is not null\").withColumn(\"breakID\", when(outputDF['breakevent'] == \"start of break\", concat(outputDF['trip_id'],outputDF['timestamp'])).when(outputDF['breakevent'] == \"end of break\", concat(outputDF['trip_id'], lag(outputDF['timestamp'], 1).over(overColumns)))).groupBy(\"breakID\").agg(F.first(outputDF['timestamp']), F.last(outputDF['timestamp']), F.first(outputDF['speed']), F.last(outputDF['speed'])).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2_m7q4TESe4",
        "outputId": "e57f084a-f71a-46cf-939e-5364567b0172"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------------------+----------------------+-------------------+------------------+\n",
            "|    breakID|first(timestamp, false)|last(timestamp, false)|first(speed, false)|last(speed, false)|\n",
            "+-----------+-----------------------+----------------------+-------------------+------------------+\n",
            "|11538204223|             1538204223|            1538204225|               54.6|             47.89|\n",
            "|11538204194|             1538204194|            1538204197|              42.14|             32.22|\n",
            "+-----------+-----------------------+----------------------+-------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "T1tS_HdpHoIt"
      },
      "execution_count": 217,
      "outputs": []
    }
  ]
}